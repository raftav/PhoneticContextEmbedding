# EXPERIMENT NUMBER 1 
## optimizer : adam 
## number of hidden layers : 2 
## number of hidden units : 50 
## learning rate : 0.000100 
## batch size : 1 
## approx number of steps: 18480000 
## approx number of steps per epoch: 3696 
1	1.99152179	1.43193678
2	1.37217133	1.29534876
3	1.27919866	1.25004094
4	1.23035187	1.20185594
5	1.19563648	1.17504085
6	1.16980817	1.14603537
7	1.15153354	1.13109407
8	1.13677534	1.11108566
9	1.12319194	1.12173461
10	1.11473523	1.10338133
11	1.10558375	1.09060735
12	1.09776223	1.08515620
13	1.09064729	1.09803545
14	1.08543638	1.08024270
15	1.08032619	1.07216382
16	1.07372198	1.09254438
17	1.07017583	1.06353309
18	1.06561772	1.06877710
19	1.06174863	1.05787377
20	1.05785404	1.05781098
21	1.05407602	1.05358333
22	1.05097021	1.05772188
23	1.04835295	1.05292687
24	1.04459248	1.04813821
25	1.04238719	1.05818273
26	1.04005313	1.04472314
27	1.03712730	1.04744286
28	1.03437628	1.04225015
29	1.03170503	1.04021088
30	1.02937568	1.03879448
31	1.02720295	1.04461982
32	1.02549523	1.04388755
33	1.02337996	1.03501453
34	1.02163006	1.04085889
35	1.01937856	1.03570841
36	1.01737193	1.04021059
37	1.01540293	1.03002050
38	1.01420355	1.03676391
39	1.01183452	1.03294916
40	1.01024389	1.03606914
41	1.00869547	1.03078810
42	1.00719505	1.02826802
43	1.00605175	1.02622312
44	1.00401291	1.02286960
45	1.00227584	1.02535370
46	1.00117862	1.02316094
47	0.99949519	1.02669093
48	0.99791408	1.02596949
49	0.99728256	1.02451824
50	0.99578390	1.03285667
51	0.99468806	1.02800322
52	0.99300879	1.02926469
53	0.99190061	1.02215417
54	0.99052740	1.02739514
55	0.98930460	1.02545408
56	0.98831910	1.02103704
57	0.98696405	1.02145202
58	0.98589590	1.02379318
59	0.98450639	1.02561902
60	0.98379838	1.02282900
61	0.98252027	1.02081142
62	0.98098389	1.02909216
63	0.98010594	1.02633660
64	0.97914288	1.02152672
65	0.97864631	1.02537252
66	0.97709627	1.02148086
67	0.97630973	1.02679958
68	0.97485606	1.02249066
69	0.97387559	1.02070474
70	0.97271485	1.02213323
71	0.97255851	1.02567224
72	0.97051969	1.02394165
73	0.96993176	1.03302697
74	0.96927872	1.03481438
75	0.96820191	1.02837480
76	0.96703381	1.02526088
77	0.96599622	1.02881745
78	0.96543328	1.01915274
79	0.96463756	1.02152075
80	0.96399653	1.03352508
81	0.96213889	1.02634742
82	0.96182546	1.02983463
83	0.96138706	1.02313398
84	0.96050158	1.02452067
85	0.96023346	1.02129411
86	0.95839605	1.02286987
87	0.95766438	1.02251234
88	0.95678997	1.03580136
89	0.95646764	1.02429522
90	0.95563155	1.02684435
